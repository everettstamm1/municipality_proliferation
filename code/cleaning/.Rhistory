for(i in 2:(2*n-2)){
len <- 2*n
head <- substr(str,1,i-1)
tail <- substr(str,i+2,len)
swap <- str_c(substr(str,i+1,i+1),substr(str,i,i))
str <- str_c(head,swap,tail)
list <- c(list,str)
}
return(list)
}
final(1)
final(2)
final(3)
final(4)
final(5)
for(i in chars){
print(i)
}
chars <- ['(',')']
chars <- ['\(','\)']
chars <-c('(',')')
for(i in chars){
print(i)
}
m <- rep(chars)
m <- rep(chars,5)
m <- cbind(chars,rep(chars,4))
m <- cbind(data.frame(),rep(chars,4))
chars <-data.frame('(',')')
chars <-data.frame(c('(',')'))
m <- cbind(chars,rep(chars,4))
?apply
apply(m,'+')
apply(m,MARGIN = 1,'+')
apply(m,MARGIN = 1,str_c)
View(m)
apply(m,MARGIN = 2,str_c)
x <- lapply(5,function(x) c('(',')'))
expand.grid(x)
x
expand.grid(rep(c('(',')'),5))
permutations <- function(n){
if(n==1){
return(matrix(1))
} else {
sp <- permutations(n-1)
p <- nrow(sp)
A <- matrix(nrow=n*p,ncol=n)
for(i in 1:n){
A[(i-1)*p+1:p,] <- cbind(i,sp+(sp>=i))
}
return(A)
}
}
permutations(5)
permutations(2)
permutations(3)
permutations(4)
library(nycflights13)
install.packages('nycflights13')
library(nycflights13)
flights
install.packages('stargazer')
?nycflights13
nycflights13
View(weather)
View(flights)
len(unique(weather$origin))
length(unique(weather$origin))
table(weather$origin)
length(unique(weather$origin,weather$year))
length(unique(c(weather$origin,weather$year)))
length(unique(c(weather$origin,weather$year,weather$month)))
length(unique(c(weather$origin,weather$year,weather$month,weather$day)))
length(unique(c(weather$origin,weather$year,weather$month,weather$day,weather$hour)))
length(unique(weather))
library(tidyverse)
temps <- weather %>%
group_by(origin,year,month,day,hour) %>%
summarise(avg_precip = mean(precip))
View(temps)
table(temps$avg_precip)
library(tidyverse)
library(nycflights13)
View(weather)
temps <- weather %>%
group_by(origin,year,month,day,hour) %>%
summarise(avg_precip = mean(precip))
View(temps)
temps <- weather %>%
group_by(origin,year,month,day,hour) %>%
summarise(avg_precip = mean(precip, na.rm = T))
flights_temps <- flights %>%
left_join(temps,
by = c('origin','year','month','day','hour'))
View(flights_temps)
colnames(flights_temps)
force(airlines)
force(airports)
force(planes)
View(airlines)
View(flights)
View(airports)
View(flights)
View(airports)
View(airports)
View(planes)
View(weather)
View(flights)
colnames(flights)
View(flights)
install.packages('rvest')
library(tidyverse)
library(rvest)
url_faculty <- 'https://www.bu.edu/econ/people/faculty/'
# Extract
webc <- rvest::read_html(url_faculty)
View(webc)
xml_child(webc, 1)
xml_attrs(webc)
webc
webc[1]
webc[2]
webc$node
webc$cod
webc[[1]]
faculty_list <- webc %>%
html_elements("li.profile-item")
View(faculty_list)
faculty_list[[1]]
library(tidyverse)
library(rvest)
url_faculty <- 'https://www.bu.edu/econ/people/faculty/'
# Extract html
webc <- rvest::read_html(url_faculty)
# Extract list
faculty_list <- webc %>%
html_elements("li.profile-item")
# Empty data frame
BU_faculty_df <- data.frame()
# Loop to extract name, position, website
for(i in 1:length(faclist)){
name <- faclist[i] %>% html_elements('h6.profile-name') %>% html_text
position <- faclist[i] %>% html_elements('p.profile-title') %>% html_text
website <- faclist[i] %>% html_elements('a.profile-link') %>% html_attr(name='href')
stopifnot(length(name)==1 & length(position)==1 & length(website)==1)
row <- cbind(name,position,website)
BU_faculty_df[i] <- row
}
# Extract list
faclist <- webc %>%
html_elements("li.profile-item")
# Empty data frame
BU_faculty_df <- data.frame()
# Loop to extract name, position, website
for(i in 1:length(faclist)){
name <- faclist[i] %>% html_elements('h6.profile-name') %>% html_text
position <- faclist[i] %>% html_elements('p.profile-title') %>% html_text
website <- faclist[i] %>% html_elements('a.profile-link') %>% html_attr(name='href')
stopifnot(length(name)==1 & length(position)==1 & length(website)==1)
row <- cbind(name,position,website)
BU_faculty_df[i] <- row
}
# Vector
name <- faclist %>% html_element('h6.profile-name') %>% html_text
position <- faclist %>% html_element('p.profile-title') %>% html_text
website <- faclist %>% html_element('a.profile-link') %>% html_attr(name='href')
BU_faculty_df <- data.frame(name,position,website)
View(BU_faculty_df)
temp_web <- read_html(website)
website[1]
# Reading fields
for(i in 1:length(website)){
temp_web <- read_html(website[i])
field <- temp_web %>% html_elements('b') %>% html_text
# If multiple rows are extracted, take the element with "fields" in the text
#field <- field[grepl("Fields")]
BU_faculty_df$fields[i] <- field
}
# Reading fields
for(i in 1:length(website)){
temp_web <- read_html(website[i])
field <- temp_web %>% html_elements('b') %>% html_text
# If multiple rows are extracted, take the element with "fields" in the text
#field <- field[grepl("Fields")]
BU_faculty_df$fields[i] <- field
}
View(BU_faculty_df)
website[2]
# Reading fields
for(i in 1:length(website)){
temp_web <- read_html(website[i])
field <- temp_web %>% html_elements('b') %>% html_text
# If multiple rows are extracted, take the element with "fields" in the text
field <- field[grepl("Fields",field,fixed = TRUE)==TRUE]
field <- sub("Fields: ",'',field)
stopifnot(length(field)<=1)
if(length(field)==0){
field <- ""
}
BU_faculty_df$fields[i] <- field
}
install.packages('jsonlite')
library(jsonlite)
url <-"https://nominatim.openstreetmap.org/search?q=270+Bay+State+
Rd+Boston+MA&format=json"
out <- fromJSON(url)
url <-"https://nominatim.openstreetmap.org/search?q=270+Bay+State+Rd+Boston+MA&format=json"
out <- fromJSON(url)
View(out)
View(out)
install.packages('tidycensus')
library(tidycensus)
census_api_key("7345c79e7ae2c2bb2c6f7f491f16fe2298fa31bc", install = TRUE)
readRenviron("~/.Renviron")
getwd()
## Load dependencies, install if not already.
packages <-
c('tidyverse',
'rvest',
'httr')
for (pkg in packages) {
if (require(pkg, character.only = TRUE) == FALSE) {
print(paste0("Trying to install ", pkg))
install.packages(pkg)
if (require(pkg, character.only = TRUE)) {
print(paste0(pkg, " installed and loaded"))
} else{
stop(paste0("could not install ", pkg))
}
}
}
getwd()
?read_excel
??read_excel
## Load dependencies, install if not already.
packages <-
c('tidyverse',
'rvest',
'httr',
'readxl')
for (pkg in packages) {
if (require(pkg, character.only = TRUE) == FALSE) {
print(paste0("Trying to install ", pkg))
install.packages(pkg)
if (require(pkg, character.only = TRUE)) {
print(paste0(pkg, " installed and loaded"))
} else{
stop(paste0("could not install ", pkg))
}
}
}
df <- read_excel("C:/Users/edog9/Dropbox/expulsion_towns/spreadsheet.xlsx")
View(df)
?read_excel
df <- read_excel("C:/Users/edog9/Dropbox/expulsion_towns/spreadsheet.xlsx", skip = 1)
View(df)
test <- df$link[355]
page <- read_html(test)
View(page)
titles <- page %>%
html_nodes(".article-title") %>%  # Use the appropriate CSS selector for the titles
html_text()
??xml_child
install.packages('xml2')
## Load dependencies, install if not already.
packages <-
c('tidyverse',
'rvest',
'httr',
'readxl')
for (pkg in packages) {
if (require(pkg, character.only = TRUE) == FALSE) {
print(paste0("Trying to install ", pkg))
install.packages(pkg)
if (require(pkg, character.only = TRUE)) {
print(paste0(pkg, " installed and loaded"))
} else{
stop(paste0("could not install ", pkg))
}
}
}
df <- read_excel("C:/Users/edog9/Dropbox/expulsion_towns/spreadsheet.xlsx", skip = 1)
test <- df$link[355]
page <- read_html(test)
titles <- page %>%
html_nodes(".article-title") %>%  # Use the appropriate CSS selector for the titles
html_text()
print()
print(titles)
page
xml_child(page, 1)
library(xml2)
xml_child(page, 1)
## Load dependencies, install if not already.
packages <-
c('tidyverse',
'rvest',
'httr',
'readxl',
'xml2')
x <- page %>%
xml_child(1)
y <- page %>%
xml_child(2)
z <- page %>%
xml_child(3)
View(x)
xml_attrs(xml_child(x, 6))[["content"]]
xml_attrs(xml_child(x, 16))[["content"]]
View(y)
signin_url <- "https://www.newspapers.com/signin/"
username <- "ptesta@tulane.edu"
password <- "Sund0wn!123"
login <- list(username = "ptesta@tulane.edu",
password = "Sund0wn!123")
session <- html_session(signin_url)
session <- sesion(signin_url)
session <- session(signin_url)
login_response <- session %>%
submit_form(
form = html_form(session)[[1]], # Use the first form on the page
submit = "Login",
login_payload
)
login_response <- session %>%
session_submit(
form = html_form(session)[[1]], # Use the first form on the page
submit = "Login",
login_payload
)
View(session)
html_form(session)[[1]]
session <- session(signin_url)
session <- session(signin_url, user_agent_string = user_agent_string)
user_agent_string <- "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
session <- session(signin_url, user_agent_string = user_agent_string)
## Load dependencies, install if not already.
packages <-
c('tidyverse',
'rvest',
'httr',
'readxl',
'xml2',
"RSelenium")
for (pkg in packages) {
if (require(pkg, character.only = TRUE) == FALSE) {
print(paste0("Trying to install ", pkg))
install.packages(pkg)
if (require(pkg, character.only = TRUE)) {
print(paste0(pkg, " installed and loaded"))
} else{
stop(paste0("could not install ", pkg))
}
}
}
## Load dependencies, install if not already.
packages <-
c('tidyverse',
'rvest',
'httr',
'readxl',
'xml2',
"RSelenium",
'wdman')
for (pkg in packages) {
if (require(pkg, character.only = TRUE) == FALSE) {
print(paste0("Trying to install ", pkg))
install.packages(pkg)
if (require(pkg, character.only = TRUE)) {
print(paste0(pkg, " installed and loaded"))
} else{
stop(paste0("could not install ", pkg))
}
}
}
rD <- rsDriver(browser = "chrome", chromever = "latest")
## Load dependencies, install if not already.
packages <-
c('tidyverse',
'rvest',
'httr',
'readxl',
'xml2',
"RSelenium",
'wdman')
for (pkg in packages) {
if (require(pkg, character.only = TRUE) == FALSE) {
print(paste0("Trying to install ", pkg))
install.packages(pkg)
if (require(pkg, character.only = TRUE)) {
print(paste0(pkg, " installed and loaded"))
} else{
stop(paste0("could not install ", pkg))
}
}
}
rD <- rsDriver(browser = "chrome", chromever = "latest")
## Load dependencies, install if not already.
packages <-
c('tidyverse',
'rvest',
'httr',
'readxl',
'xml2',
"RSelenium",
'wdman')
for (pkg in packages) {
if (require(pkg, character.only = TRUE) == FALSE) {
print(paste0("Trying to install ", pkg))
install.packages(pkg)
if (require(pkg, character.only = TRUE)) {
print(paste0(pkg, " installed and loaded"))
} else{
stop(paste0("could not install ", pkg))
}
}
}
rD <- rsDriver(browser = "chrome", chromever = "latest")
## Load dependencies, install if not already.
packages <-
c('tidyverse',
'sf',
'haven',
'tigris',
'stringr',
'readxl',
'terra')
for (pkg in packages) {
if (require(pkg, character.only = TRUE) == FALSE) {
print(paste0("Trying to install ", pkg))
install.packages(pkg)
if (require(pkg, character.only = TRUE)) {
print(paste0(pkg, " installed and loaded"))
} else{
stop(paste0("could not install ", pkg))
}
}
}
# Get paths
paths <- read.csv("../../paths.csv")
getwd()
for (pkg in packages) {
if (require(pkg, character.only = TRUE) == FALSE) {
print(paste0("Trying to install ", pkg))
install.packages(pkg)
if (require(pkg, character.only = TRUE)) {
print(paste0(pkg, " installed and loaded"))
} else{
stop(paste0("could not install ", pkg))
}
}
}
## Load dependencies, install if not already.
packages <-
c('tidyverse',
'sf',
'haven',
'tigris',
'stringr',
'readxl',
'terra')
for (pkg in packages) {
if (require(pkg, character.only = TRUE) == FALSE) {
print(paste0("Trying to install ", pkg))
install.packages(pkg)
if (require(pkg, character.only = TRUE)) {
print(paste0(pkg, " installed and loaded"))
} else{
stop(paste0("could not install ", pkg))
}
}
}
# Get paths
paths <- read.csv("../../paths.csv")
getwd()
cd("../../..")
setwd("../../..")
getwd()
setwd("edog9/Documents/Github/Municipality_proliferation")
setwd("code/cleaning")
# Get paths
paths <- read.csv("../../paths.csv")
RAWDATA <- paths[paths$global == "RAWDATA",2]
INTDATA <- paths[paths$global == "INTDATA",2]
CLEANDATA <- paths[paths$global == "CLEANDATA",2]
FIGS <- paths[paths$global == "FIGS",2]
XWALKS <- paths[paths$global == "XWALKS",2]
munis <- st_read(paste0(CLEANDATA,"/other/municipal_shapefile/municipal_shapefile_v2.shp"))
crs <- st_crs(munis) # NAD 83
school_districts <- read.csv(paste0(RAWDATA,"/nces/school-districts_lea_directory.csv")) %>%
filter(!is.na(longitude) & !is.na(latitude) & year == 2017) %>%
st_as_sf(coords = c("longitude", "latitude"), crs = crs)
schools <- read_dta(paste0(INTDATA,"/nces/school_ccd_directory.dta"))  %>%
filter(!is.na(longitude) & !is.na(latitude) & year == 2017) %>%
st_as_sf(coords = c("longitude", "latitude"), crs = crs)
matched_districts <- st_join(school_districts, munis, join = st_within)
matched_schools <- st_join(schools, munis, join = st_within)
output_districts <- matched_districts %>%
st_drop_geometry() %>%
select(PLACEFP, STATEFP,leaid) %>%
filter(!is.na(leaid) & !is.na(PLACEFP)) %>%
distinct()
output_schools <- matched_schools %>%
st_drop_geometry() %>%
select(PLACEFP, STATEFP,leaid, ncessch) %>%
filter(!is.na(leaid) & !is.na(PLACEFP) & !is.na(ncessch)) %>%
distinct()
check <- read_dta(paste0(XWALKS,'/ncessch_place_xwalk.dta'))
school_districts <- read.csv(paste0(RAWDATA,"/nces/school-districts_lea_directory.csv"))
write_dta(output_districts,path=paste0(XWALKS,"/leaid_place_xwalk.dta"))
write_dta(output_schools,path=paste0(XWALKS,"/ncessch_place_xwalk.dta"))
